#!/usr/bin/env python
"""
äº¤äº’å¼GPT-OSS Metalç”Ÿæˆè„šæœ¬
å¯ä»¥æŒç»­è¾“å…¥æç¤ºè¯è¿›è¡Œå¯¹è¯
"""

import os
from gpt_oss.metal import Context, Model

def main():
    # é…ç½®è®¾ç½®
    MODEL_PATH = "gpt-oss-20b/metal/model.bin"  # æ¨¡å‹è·¯å¾„
    MAX_TOKENS = 100                           # æ¯æ¬¡æœ€å¤§ç”Ÿæˆtokenæ•°
    CONTEXT_LENGTH = 2048                      # ä¸Šä¸‹æ–‡é•¿åº¦
    
    print("ğŸš€ GPT-OSS Metal äº¤äº’å¼ç”Ÿæˆå™¨")
    print("=" * 50)
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    print(f"ğŸ¯ æ¯æ¬¡æœ€å¤§tokenæ•°: {MAX_TOKENS}")
    print(f"ğŸ“ ä¸Šä¸‹æ–‡é•¿åº¦: {CONTEXT_LENGTH}")
    print("ğŸ’¡ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç¨‹åº")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {MODEL_PATH}")
        print("è¯·ç¡®ä¿å·²ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°æ­£ç¡®ä½ç½®")
        return
    
    try:
        # åŠ è½½æ¨¡å‹
        print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        model = Model(MODEL_PATH)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\n")
        
        while True:
            # è·å–ç”¨æˆ·è¾“å…¥
            prompt = input("ğŸ‘¤ è¯·è¾“å…¥æç¤ºè¯: ").strip()
            
            # é€€å‡ºæ¡ä»¶
            if prompt.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§!")
                break
            
            if not prompt:
                print("âš ï¸ æç¤ºè¯ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
                continue
            
            try:
                # ä¸ºæ¯æ¬¡å¯¹è¯åˆ›å»ºæ–°çš„ä¸Šä¸‹æ–‡
                print("ğŸ”„ æ­£åœ¨åˆ›å»ºä¸Šä¸‹æ–‡...")
                context = Context(model, context_length=CONTEXT_LENGTH)
                
                # æ·»åŠ æç¤ºè¯
                context.append(prompt)
                prompt_tokens = context.num_tokens
                
                print(f"ğŸ¤– GPT-OSS: ", end='', flush=True)
                
                # ç”Ÿæˆå›å¤
                tokenizer = model.tokenizer
                generated_tokens = 0
                
                while context.num_tokens - prompt_tokens < MAX_TOKENS:
                    try:
                        token = context.sample()
                        context.append(token)
                        decoded = str(tokenizer.decode(token), encoding="utf-8")
                        print(decoded, end='', flush=True)
                        generated_tokens += 1
                        
                        # æ£€æŸ¥æ˜¯å¦å®Œæˆäº†ä¸€ä¸ªå¥å­
                        if decoded in ['.', '!', '?', '\n']:
                            # å¯ä»¥é€‰æ‹©åœ¨å¥å­ç»“æŸæ—¶åœæ­¢
                            pass
                            
                    except Exception as e:
                        print(f"\nâš ï¸ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                        break
                
                print(f"\nğŸ“Š [ç”Ÿæˆäº† {generated_tokens} ä¸ªtoken]\n")
                
            except Exception as e:
                print(f"âŒ å¤„ç†æç¤ºè¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                print("ğŸ’¡ å°è¯•ä½¿ç”¨æ›´çŸ­çš„æç¤ºè¯æˆ–é‡å¯ç¨‹åº\n")
                
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å†…å­˜ (æ¨è24GB+)")
        print("2. å°è¯•å‡å°‘CONTEXT_LENGTHçš„å€¼")
        print("3. å…³é—­å…¶ä»–åº”ç”¨ç¨‹åºé‡Šæ”¾å†…å­˜")

if __name__ == '__main__':
    main()
